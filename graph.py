"""
Main LangGraph definition for the DataStory application
"""
from typing import Dict, Any, TypedDict, List, Optional, Annotated, Literal
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langgraph.checkpoint.memory import MemorySaver

from backend.config.config import get_vanna_instance
from backend.graph.nodes import *

vn = get_vanna_instance()

# Define the state for type checking
# Define the enhanced state for type checking
class State(TypedDict):
    # Input and Query Analysis
    conversation_id: str
    conversation_history: Annotated[list, add_messages]  # List of messages in the conversation
    current_question: str  # The current user query
    is_clarification_needed: bool  # Flag for whether clarification is needed
    clarification_message: Optional[str]  # Message explaining what clarification is needed
    
    # Intent Classification
    intent: Literal["sql_generation", "visualization_only", "explanation_only"]
    
    # Context Management
    context: Annotated[Dict[str, Any], "merge"]  # Context information for SQL generation
    is_context_sufficient: bool  # Flag for whether context is sufficient
    
    # SQL Generation and Validation
    generated_sql: str  # Raw SQL generated by the model
    parsed_question: str  # Parsed version of the user question
    sql_query: str  # Final SQL query to execute
    extraction_error: Optional[str]  # Error during SQL extraction
    sql_valid: bool  # Flag for whether SQL is valid
    validation_message: str  # Validation message
    has_errors: bool  # Flag for whether there are errors
    needs_human_review: bool  # Flag for whether human review is needed
    human_review_action: Optional[Literal["regenerate", "proceed", "cancel"]]  # Human review action
    human_edited_sql: Optional[str]  # SQL edited by human
    
    # Query Execution
    query_result: List[Dict[str, Any]]  # Query results
    query_error: Optional[str]  # Error during query execution
    result_dataframe: Optional[Any]  # pandas DataFrame
    has_execution_error: bool  # Flag for whether there was an execution error
    execution_successful: bool  # Flag for whether execution was successful
    
    # Result Processing
    needs_training: bool  # Flag for whether training is needed
    needs_visualization: bool  # Flag for whether visualization is needed
    results_sufficient: bool  # Flag for whether results are sufficient
    
    # Summary and Visualization - Annotated for concurrent updates
    summary: Annotated[str, "override"]  # From generate_summary
    summary_error: Annotated[Optional[str], "last_value"]  # From generate_summary
    plotly_code: Annotated[Optional[str], "override"]  # From generate_plotly_code
    plotly_figure: Annotated[Optional[Dict], "override"]  # From get_plotly_figure
    visualization_error: Annotated[Optional[str], "last_value"]  # For visualization errors
    
    # Human Feedback
    human_feedback: Optional[Literal["refine_sql", "improve_viz", "add_context"]]  # Human feedback
    
    # Output
    execution_time: float
    agent_messages: Annotated[List[Dict[str, Any]], "append"]  # Messages from the agent
    user_request: Optional[Literal["new_query", "end"]]  # User request for next action


# Create the graph
def create_graph():
    """
    Create the DataStory graph
    
    Returns:
        The compiled graph
    """
    # Initialize a new graph
    graph = StateGraph(State)
    
    # Add all nodes
    graph.add_node("query_analyzer", query_analyzer)
    graph.add_node("human_input", human_input_node)
    graph.add_node("intent_classifier", intent_classifier)
    graph.add_node("generate_sql", generate_sql) 
    graph.add_node("intermediate_check", intermediate_check)
    graph.add_node("context_enhancer", context_enhancer)
    graph.add_node("extract_sql", extract_sql)
    graph.add_node("validate_sql", validate_sql) 
    graph.add_node("human_sql_review", human_sql_review)
    graph.add_node("error_handler", error_handler)
    graph.add_node("run_sql", run_sql)
    graph.add_node("result_processor", result_processor)
    graph.add_node("training_agent", training_agent)
    graph.add_node("visualization_check", visualization_check)
    graph.add_node("generate_summary", generate_summary)  
    graph.add_node("generate_plotly_code", generate_plotly_code) 
    graph.add_node("get_plotly_figure", get_plotly_figure) 
    graph.add_node("result_check", result_check)
    graph.add_node("human_feedback_node", human_feedback_node)
    graph.add_node("explainer", explainer)
    
    # Define the flow - Start with query analysis
    graph.add_edge(START, "query_analyzer")
    
    # Conditional edge from query analyzer
    def route_after_query_analysis(state: Dict[str, Any]) -> str:
        if state.get("is_clarification_needed", False):
            return "human_input"
        return "intent_classifier"
    
    graph.add_conditional_edges("query_analyzer", route_after_query_analysis, {
        "human_input": "human_input",
        "intent_classifier": "intent_classifier"
    })
    
    # Human input goes to intent classifier
    graph.add_edge("human_input", "intent_classifier")

     # Conditional edge from intent classifier
    def route_after_intent_classification(state: Dict[str, Any]) -> str:
        intent = state.get("intent", "sql_generation")
        if intent == "sql_generation":
            return "generate_sql"
        elif intent == "visualization_only":
            return "visualization_check"
        elif intent == "explanation_only":
            return "explainer"
        return "generate_sql"  # Default
    
    graph.add_conditional_edges("intent_classifier", route_after_intent_classification, {
        "generate_sql": "generate_sql",
        "visualization_only": "visualization_check",
        "explanation_only": "explainer",
        "generate_sql": "generate_sql"
    })
    
    # SQL generation path
    graph.add_edge("generate_sql", "intermediate_check")
    
    # Conditional edge from intermediate check
    def route_after_intermediate_check(state: Dict[str, Any]) -> str:
        if state.get("is_context_sufficient", True):
            return "extract_sql"
        return "context_enhancer"
    
    graph.add_conditional_edges("intermediate_check", route_after_intermediate_check, {
        "extract_sql": "extract_sql",
        "context_enhancer": "context_enhancer"
    })

    # Validate SQL path
    graph.add_edge("extract_sql", "validate_sql")
    
    # Context enhancer loops back to SQL generation
    graph.add_edge("context_enhancer", "generate_sql")
    
    # Conditional edge from SQL validation
    def route_after_validation(state: Dict[str, Any]) -> str:
        if state.get("has_errors", False):
            return "error_handler"
        elif state.get("needs_human_review", False):
            return "human_sql_review"
        return "run_sql"
    
    graph.add_conditional_edges("validate_sql", route_after_validation, {
        "error_handler": "error_handler",
        "human_sql_review": "human_sql_review",
        "run_sql": "run_sql"
    })
    
    # Error handler goes back to SQL generation
    graph.add_edge("error_handler", "generate_sql")
    
    # Conditional edge from human SQL review
    def route_after_human_review(state: Dict[str, Any]) -> str:
        action = state.get("human_review_action", "regenerate")
        if action == "regenerate":
            return "submit_prompt"
        elif action == "proceed":
            return "run_sql"
        return END  # Cancel
    
    graph.add_conditional_edges("human_sql_review", route_after_human_review, {
        "generate_sql": "generate_sql",
        "run_sql": "run_sql",
        END: END
    })
    
    # Conditional edge from SQL execution
    def route_after_execution(state: Dict[str, Any]) -> str:
        if state.get("has_execution_error", False):
            return "error_handler"
        return "result_processor"
    
    graph.add_conditional_edges("run_sql", route_after_execution, {
        "error_handler": "error_handler",
        "result_processor": "result_processor"
    })
    
    # Conditional edge from result processor
    def route_after_result_processing(state: Dict[str, Any]) -> str:
        if state.get("needs_training", False):
            return "training_agent"
        return "visualization_check"
    
    graph.add_conditional_edges("result_processor", route_after_result_processing, {
        "training_agent": "training_agent",
        "visualization_check": "visualization_check"
    })
    
    # Training agent goes to visualization check
    graph.add_edge("training_agent", "visualization_check")
    
    # Conditional edge from visualization check
    def route_after_visualization_check(state: Dict[str, Any]) -> str:
        if state.get("needs_visualization", True):
            return "generate_plotly_code"
        return "result_check"
    
    graph.add_conditional_edges("visualization_check", route_after_visualization_check, {
        "generate_plotly_code": "generate_plotly_code",
        "result_check": "result_check"
    })

    # Conditional edge from plotly code generation
    # Define a conditional edge for plotly code generation
    def route_after_plotly_code(state: Dict[str, Any]) -> str:
        """Route to get_plotly_figure if we have code, otherwise go directly to END"""
        print(f"[DEBUG] route_after_plotly_code - Checking if we have Plotly code")
        if state.get("plotly_code"):
            print(f"[DEBUG] route_after_plotly_code - Plotly code available, going to figure creation")
            return "get_plotly_figure"
        else:
            print(f"[DEBUG] route_after_plotly_code - No Plotly code, skipping figure creation")
            return END
    
    # Visualization generation path (similar to existing)
    graph.add_conditional_edges("generate_plotly_code", route_after_plotly_code, {
        "get_plotly_figure": "get_plotly_figure",
        END: END
    })
    graph.add_edge("get_plotly_figure", "result_check")
    
    # Generate summary in parallel with visualization
    graph.add_edge("visualization_check", "generate_summary")
    graph.add_edge("generate_summary", "result_check")
    
    # Conditional edge from result check
    def route_after_result_check(state: Dict[str, Any]) -> str:
        if state.get("results_sufficient", True):
            return "explainer"
        return "human_feedback_node"
    
    graph.add_conditional_edges("result_check", route_after_result_check, {
        "explainer": "explainer",
        "human_feedback_node": "human_feedback_node"
    })
    
    # Conditional edge from human feedback
    def route_after_human_feedback(state: Dict[str, Any]) -> str:
        feedback = state.get("human_feedback", "refine_sql")
        if feedback == "refine_sql":
            return "generate_sql"
        elif feedback == "improve_viz":
            return "generate_plotly_code"
        elif feedback == "add_context":
            return "context_enhancer"
        return "explainer"  # Default
    
    graph.add_conditional_edges("human_feedback_node", route_after_human_feedback, 
                                {
                                    "generate_sql": "generate_sql",
                                    "generate_plotly_code": "generate_plotly_code",
                                    "context_enhancer": "context_enhancer",
                                    "explainer": "explainer"
                                })
    
    # Explainer goes to output
    graph.add_edge("explainer", END)
    
    # # Conditional edge from output
    # def route_after_output(state: Dict[str, Any]) -> str:
    #     request = state.get("user_request", "end")
    #     if request == "new_query":
    #         return START
    #     return END
    
    # graph.add_conditional_edges("output_node", route_after_output, {
    #     START: START,
    #     END: END
    # })
    
    # Compile the graph
    graph_run = graph.compile()
    return graph_run


# Create a singleton instance of the graph
datastory_graph = create_graph()  # Keeping the variable name for backward compatibility


